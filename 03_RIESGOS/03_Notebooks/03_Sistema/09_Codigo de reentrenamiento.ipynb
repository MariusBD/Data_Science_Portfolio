{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797ae63f",
   "metadata": {},
   "source": [
    "## CODIGO DE RE-ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64445de1",
   "metadata": {},
   "source": [
    "*NOTA: Para poder usar este código de entrenamiento hay que lanzarlo desde exactamente el mismo entorno en el que fue creado.*\n",
    "\n",
    "*Se puede instalar ese entorno en la nueva máquina usando el environment.yml que creamos en el set up del proyecto*\n",
    "\n",
    "*Copiar el riesgos.yml al directorio y en el terminal o anaconda prompt ejecutar:*\n",
    "\n",
    "conda env create --file riesgos.yml --name riesgos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe7be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marius\\miniconda3\\envs\\riesgos\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marius\\miniconda3\\envs\\riesgos\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marius\\miniconda3\\envs\\riesgos\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#1.LIBRERIAS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "#2.CARGA DATOS\n",
    "ruta_proyecto = 'C:/Users/Marius/EstructuraDirectorio/03_MACHINE_LEARNING/06_CASOS/03_RIESGOS'\n",
    "nombre_fichero_datos = 'prestamos.csv'\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "df = pd.read_csv(ruta_completa,index_col=0)\n",
    "\n",
    "\n",
    "#3.VARIABLES Y REGISTROS FINALES\n",
    "variables_finales = ['ingresos_verificados',\n",
    "                     'vivienda',\n",
    "                     'finalidad',\n",
    "                     'num_cuotas',\n",
    "                     'antigüedad_empleo',\n",
    "                     'rating',\n",
    "                     'ingresos',\n",
    "                     'dti',\n",
    "                     'num_lineas_credito',\n",
    "                     'porc_uso_revolving',\n",
    "                     'principal',\n",
    "                     'tipo_interes',\n",
    "                     'imp_cuota',\n",
    "                     'num_derogatorios',\n",
    "                     'estado',\n",
    "                     'imp_amortizado',\n",
    "                     'imp_recuperado'\n",
    "                  ]\n",
    "a_eliminar = df.loc[df.ingresos > 300000].index.values\n",
    "df = df[~df.index.isin(a_eliminar)]\n",
    "df = df[variables_finales]\n",
    "\n",
    "\n",
    "#4.FUNCIONES DE SOPORTE\n",
    "def calidad_datos(temp):\n",
    "    temp['antigüedad_empleo'] = temp['antigüedad_empleo'].fillna('desconocido')\n",
    "    temp.update(temp.select_dtypes('number').fillna(value = 0))\n",
    "    return(temp)\n",
    "\n",
    "def creacion_variables_pd(df):\n",
    "    temp = df.copy()\n",
    "    temp['target_pd'] = np.where(temp.estado.isin(['Charged Off','Does not meet the credit policy. Status:Charged Off','Default']), 1, 0)\n",
    "    temp.vivienda = temp.vivienda.replace(['ANY','NONE','OTHER'],'MORTGAGE')\n",
    "    temp.finalidad = temp.finalidad.replace(['wedding','educational','renewable_energy'],'otros')\n",
    "    #Eliminamos las variables que ya no usaremos\n",
    "    temp.drop(columns = ['estado','imp_amortizado','imp_recuperado'],inplace = True)\n",
    "    #Separamos entre predictoras y target\n",
    "    temp_x = temp.iloc[:,:-1]\n",
    "    temp_y = temp.iloc[:,-1]\n",
    "    return(temp_x,temp_y)\n",
    "\n",
    "def creacion_variables_ead(df):\n",
    "    temp = df.copy()\n",
    "    temp['pendiente'] = temp.principal - temp.imp_amortizado\n",
    "    temp['target_ead'] = temp.pendiente / temp.principal\n",
    "    temp.vivienda = temp.vivienda.replace(['ANY','NONE','OTHER'],'MORTGAGE')\n",
    "    temp.finalidad = temp.finalidad.replace(['wedding','educational','renewable_energy'],'otros')\n",
    "    #Eliminamos las variables que ya no usaremos\n",
    "    temp.drop(columns = ['estado','imp_amortizado','imp_recuperado','pendiente'],inplace = True)\n",
    "    #Separamos entre predictoras y target\n",
    "    temp_x = temp.iloc[:,:-1]\n",
    "    temp_y = temp.iloc[:,-1]\n",
    "    return(temp_x,temp_y)\n",
    "\n",
    "def creacion_variables_lgd(df):\n",
    "    temp = df.copy()\n",
    "    temp['pendiente'] = temp.principal - temp.imp_amortizado\n",
    "    temp['target_lgd'] = 1 - (temp.imp_recuperado / temp.pendiente)\n",
    "    temp['target_lgd'].fillna(0,inplace=True)\n",
    "    temp.vivienda = temp.vivienda.replace(['ANY','NONE','OTHER'],'MORTGAGE')\n",
    "    temp.finalidad = temp.finalidad.replace(['wedding','educational','renewable_energy'],'otros')\n",
    "    #Eliminamos las variables que ya no usaremos\n",
    "    temp.drop(columns = ['estado','imp_amortizado','imp_recuperado','pendiente'],inplace = True)\n",
    "    #Separamos entre predictoras y target\n",
    "    temp_x = temp.iloc[:,:-1]\n",
    "    temp_y = temp.iloc[:,-1]\n",
    "    return(temp_x,temp_y)\n",
    "\n",
    "\n",
    "#5.CALIDAD Y CREACION DE VARIABLES\n",
    "x_pd, y_pd = creacion_variables_pd(calidad_datos(df))\n",
    "x_ead, y_ead = creacion_variables_ead(calidad_datos(df))\n",
    "x_lgd, y_lgd = creacion_variables_pd(calidad_datos(df))\n",
    "\n",
    "\n",
    "#6.CARGA PIPES DE ENTRENAMIENTO\n",
    "ruta_pipe_entrenamiento_pd = ruta_proyecto + '/04_Modelos/pipe_entrenamiento_pd.pickle'\n",
    "ruta_pipe_entrenamiento_ead = ruta_proyecto + '/04_Modelos/pipe_entrenamiento_ead.pickle'\n",
    "ruta_pipe_entrenamiento_lgd = ruta_proyecto + '/04_Modelos/pipe_entrenamiento_lgd.pickle'\n",
    "\n",
    "with open(ruta_pipe_entrenamiento_pd, mode='rb') as file:\n",
    "    pipe_entrenamiento_pd = pickle.load(file)\n",
    "\n",
    "with open(ruta_pipe_entrenamiento_ead, mode='rb') as file:\n",
    "    pipe_entrenamiento_ead = pickle.load(file)\n",
    "\n",
    "with open(ruta_pipe_entrenamiento_lgd, mode='rb') as file:\n",
    "    pipe_entrenamiento_lgd = pickle.load(file)\n",
    "\n",
    "\n",
    "#7.ENTRENAMIENTO\n",
    "pipe_ejecucion_pd = pipe_entrenamiento_pd.fit(x_pd,y_pd)\n",
    "pipe_ejecucion_ead = pipe_entrenamiento_ead.fit(x_ead,y_ead)\n",
    "pipe_ejecucion_lgd = pipe_entrenamiento_lgd.fit(x_lgd,y_lgd)\n",
    "\n",
    "\n",
    "#8.GUARDA MODELOS ENTRENADOS EN PIPE DE EJECUCION\n",
    "ruta_pipe_ejecucion_pd = ruta_proyecto + '/04_Modelos/pipe_ejecucion_pd.pickle'\n",
    "ruta_pipe_ejecucion_ead = ruta_proyecto + '/04_Modelos/pipe_ejecucion_ead.pickle'\n",
    "ruta_pipe_ejecucion_lgd = ruta_proyecto + '/04_Modelos/pipe_ejecucion_lgd.pickle'\n",
    "\n",
    "with open(ruta_pipe_ejecucion_pd, mode='wb') as file:\n",
    "    pickle.dump(pipe_ejecucion_pd, file)\n",
    "\n",
    "with open(ruta_pipe_ejecucion_ead, mode='wb') as file:\n",
    "    pickle.dump(pipe_ejecucion_ead, file)\n",
    "\n",
    "with open(ruta_pipe_ejecucion_lgd, mode='wb') as file:\n",
    "    pickle.dump(pipe_ejecucion_lgd, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0dfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
